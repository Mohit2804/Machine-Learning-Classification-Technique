# -*- coding: utf-8 -*-
"""ANN CW (CNN)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Rio2sG5-hB2w5DT-mkijNK2-Bx9CpWWQ
"""

pip install pandas as pd

pip install numpy as np

pip install mtcnn

pip install keras

pip install image

pip install Pillow

pip install touch

pip install argparse

pip install tensorflow

# Commented out IPython magic to ensure Python compatibility.
import os
import cv2
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from collections import OrderedDict
# visualization
from PIL import Image
# identifying faces
# %pip install mtcnn
from mtcnn.mtcnn import MTCNN
# visualizing bounding boxes
import matplotlib.patches as patches
# CNN
import keras
import tensorflow as tf 
tf.compat.v1.get_default_graph()
from sklearn.model_selection import train_test_split
# Moving files between directories
import shutil
from shutil import unpack_archive
from subprocess import check_output

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import cv2
from tqdm import tqdm
import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D

import pickle

dataset_path = "C:/Users/DELL/OneDrive/Desktop/lfw_dataset/lfw-deepfunneled/lfw-deepfunneled/"

lfw_allnames = pd.read_csv("C:/Users/DELL/OneDrive/Desktop/lfw_dataset/lfw_allnames.csv")
matchpairsDevTest = pd.read_csv("C:/Users/DELL/OneDrive/Desktop/lfw_dataset/matchpairsDevTest.csv")
matchpairsDevTrain = pd.read_csv("C:/Users/DELL/OneDrive/Desktop/lfw_dataset/matchpairsDevTrain.csv")
mismatchpairsDevTest = pd.read_csv("C:/Users/DELL/OneDrive/Desktop/lfw_dataset/mismatchpairsDevTest.csv")
mismatchpairsDevTrain = pd.read_csv("C:/Users/DELL/OneDrive/Desktop/lfw_dataset/mismatchpairsDevTrain.csv")
pairs = pd.read_csv("C:/Users/DELL/OneDrive/Desktop/lfw_dataset/pairs.csv")
# tidy pairs data: 
pairs = pairs.rename(columns ={'name': 'name1', 'Unnamed: 3': 'name2'})
matched_pairs = pairs[pairs["name2"].isnull()].drop("name2",axis=1)
mismatched_pairs = pairs[pairs["name2"].notnull()]
people = pd.read_csv("C:/Users/DELL/OneDrive/Desktop/lfw_dataset/people.csv")
# remove null values
people = people[people.name.notnull()]
peopleDevTest = pd.read_csv("C:/Users/DELL/OneDrive/Desktop/lfw_dataset/peopleDevTest.csv")
peopleDevTrain = pd.read_csv("C:/Users/DELL/OneDrive/Desktop/lfw_dataset/peopleDevTrain.csv")

# shape data frame so there is a row per image, matched to relevant jpg file
image_paths = lfw_allnames.loc[lfw_allnames.index.repeat(lfw_allnames['images'])]
image_paths['image_path'] = 1 + image_paths.groupby('name').cumcount()
image_paths['image_path'] = image_paths.image_path.apply(lambda x: '{0:0>4}'.format(x))
image_paths['image_path'] = image_paths.name + "/" + image_paths.name + "_" + image_paths.image_path + ".jpg"
image_paths = image_paths.drop("images",1)

# take a random sample: 80% of the data for the test set
lfw_train, lfw_test = train_test_split(image_paths, test_size=0.2)
lfw_train = lfw_train.reset_index().drop("index",1)
lfw_test = lfw_test.reset_index().drop("index",1)

# verify that there is a mix of seen and unseen individuals in the test set
print(len(set(lfw_train.name).intersection(set(lfw_test.name))))
print(len(set(lfw_test.name) - set(lfw_train.name)))

# both comprehensively non-empty - we are ok to procede.
# N.B. although we don't use this training/test split in the following model, this is the format of the data we
# would use in applying models to the full dataset

widths = []
heights = []
files = image_paths.image_path
for file in files:
    path = "sample_data/lfw-deepfunneled.zip" + str(file)
    im = Image.open(path)
    widths.append(im.width)
    heights.append(im.height)

pd.DataFrame({'height':heights,'width':widths}).describe()



hr_image = preprocess_image(image_paths)

image_paths['name'].value_counts()[:10].plot(kind = "bar")

ind_counts = image_paths.groupby('name').count().image_path
print(str(sum(ind_counts[ind_counts==1])) + " individuals, which is " + str(round(100*
(sum(ind_counts[ind_counts==1])/sum(ind_counts)))) + "% of the total individuals considered, are only represented by a single image in this dataset.")

im = Image.open('https://drive.google.com/drive/folders/1TGVXr9-i54_DcuSg25yJ2GMzH5JaEaDP?usp=sharing' + str(lfw_train.image_path[0]))
plt.imshow(im)







